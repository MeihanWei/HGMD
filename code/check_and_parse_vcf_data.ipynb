{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04d2f63",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "This ipynb did the following tasks:\n",
    "\n",
    "Check vcf data\n",
    "\n",
    "Parse column 8 into 9 additional columns\n",
    "\n",
    "Split data into different categories based on their format and save to a new .tsv file\n",
    "\n",
    "Summarize number of variants in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a2e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "\n",
    "def print_first_5_rows(vcf_path):\n",
    "    # Open VCF file\n",
    "    vcf = pysam.VariantFile(vcf_path)\n",
    "    # Print the header\n",
    "    print(vcf.header)\n",
    "    # Print first 5 records\n",
    "    print(\"\\nFirst 5 variants:\")\n",
    "    for i, record in enumerate(vcf):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        print(record)\n",
    "    vcf.close()\n",
    "\n",
    "# Example usage\n",
    "print_first_5_rows(\"/share/yu/mw2243/HGMD/2025_1_hg38_fullinfo.vcf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82445edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import pandas as pd\n",
    "from typing import Dict, Optional\n",
    "\n",
    "def parse_info_field(info_obj) -> Dict[str, Optional[str]]:\n",
    "    \"\"\"Parse VariantRecordInfo object with robust error handling\"\"\"\n",
    "    parsed = {\n",
    "        'CLASS': None,\n",
    "        'MUT': None,\n",
    "        'GENE': None,\n",
    "        'STRAND': None,\n",
    "        'DNA': None,\n",
    "        'PROT': None,\n",
    "        'DB': None,\n",
    "        'PHEN': None,\n",
    "        'RANKSCORE': None\n",
    "    }\n",
    "    try:\n",
    "        # Get all available fields\n",
    "        available_fields = list(info_obj.keys())\n",
    "        #print(f\"Available INFO fields in first record: {available_fields}\")\n",
    "        # Flexible field name mapping\n",
    "        field_mapping = {\n",
    "            'CLASS': ['CLASS', 'CLS', 'TYPE'],\n",
    "            'MUT': ['MUT', 'MUTATION', 'MUT_TYPE'],\n",
    "            'GENE': ['GENE', 'GENENAME', 'G'],\n",
    "            'STRAND': ['STRAND', 'STR'],\n",
    "            'DNA': ['DNA', 'TRANSCRIPT', 'CDNA'],\n",
    "            'PROT': ['PROT', 'PROTEIN', 'AA'],\n",
    "            'DB': ['DB', 'RS', 'DBSNP', 'RSID'],\n",
    "            'PHEN': ['PHEN', 'PHENOTYPE', 'DISEASE'],\n",
    "            'RANKSCORE': ['RANKSCORE', 'RANK', 'SCORE']\n",
    "        }\n",
    "        for target_field, possible_names in field_mapping.items():\n",
    "            for name in possible_names:\n",
    "                if name in info_obj:\n",
    "                    value = info_obj[name]\n",
    "                    if isinstance(value, (list, tuple)):\n",
    "                        value = ','.join(map(str, value))\n",
    "                    if value:\n",
    "                        value = str(value).replace('\"', '')\n",
    "                        if target_field in ['DNA', 'PROT']:\n",
    "                            value = str(value).replace('%3A', ':').replace('%2C', ',')\n",
    "                    parsed[target_field] = str(value) if value else None\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing INFO: {e}\")\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def process_vcf(input_vcf: str, output_tsv: str):\n",
    "    \"\"\"Process VCF with proper error handling\"\"\"\n",
    "    try:\n",
    "        # Open VCF without require_index parameter\n",
    "        vcf = pysam.VariantFile(input_vcf)\n",
    "        results = []\n",
    "        for i, record in enumerate(vcf):\n",
    "            # Basic variant info\n",
    "            variant_data = {\n",
    "                'CHROM': record.chrom,\n",
    "                'POS': record.pos,\n",
    "                'ID': record.id if record.id else '.',\n",
    "                'REF': record.ref,\n",
    "                'ALT': ','.join(record.alts) if record.alts else '.',\n",
    "                'QUAL': record.qual,\n",
    "                'FILTER': ','.join(record.filter) if record.filter else 'PASS'\n",
    "            }\n",
    "            # Parse INFO\n",
    "            parsed_info = parse_info_field(record.info)\n",
    "            results.append({**variant_data, **parsed_info})\n",
    "            # Debug output for first record\n",
    "            if i == 0:\n",
    "                print(\"\\nFirst record INFO content:\")\n",
    "                for k, v in record.info.items():\n",
    "                    print(f\"{k}: {v} ({type(v)})\")\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(results)\n",
    "        # Save to TSV\n",
    "        df.to_csv(output_tsv, sep='\\t', index=False)\n",
    "        print(f\"\\nSuccessfully processed {len(df)} records\")\n",
    "        print(\"Sample output:\")\n",
    "        print(df.head().to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error: {e}\")\n",
    "    finally:\n",
    "        if 'vcf' in locals():\n",
    "            vcf.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "# Process your file\n",
    "parsed_res = process_vcf(\n",
    "    \"/share/yu/mw2243/HGMD/2025_1_hg38_fullinfo.vcf\",\n",
    "    \"/share/yu/mw2243/HGMD/parsed_variants.tsv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51499805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "\n",
    "def count_vcf_records(vcf_path):\n",
    "    with pysam.VariantFile(vcf_path) as vcf:\n",
    "        count = sum(1 for _ in vcf)\n",
    "    return count\n",
    "\n",
    "num_records = count_vcf_records(\"/share/yu/mw2243/HGMD/2025_1_hg38_fullinfo.vcf\")\n",
    "print(f\"Total records: {num_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5939a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_missense_variants(input_tsv, output_tsv):\n",
    "    # Read the parsed TSV file\n",
    "    df = pd.read_csv(input_tsv, sep='\\t')\n",
    "    # Define the missense mutation pattern\n",
    "    missense_pattern = r'.+:p\\.([A-Z])(\\d+)([A-Z])'\n",
    "    # Create mask for rows with valid missense mutations\n",
    "    missense_mask = df['PROT'].str.contains(missense_pattern, na=False)\n",
    "    # Subset the dataframe\n",
    "    missense_df = df[missense_mask].copy()\n",
    "    # Extract amino acid information\n",
    "    aa_info = missense_df['PROT'].str.extract(missense_pattern)\n",
    "    # Add new columns\n",
    "    missense_df['REF_AA'] = aa_info[0]  # Reference amino acid\n",
    "    missense_df['ALT_AA'] = aa_info[2]  # Alternate amino acid\n",
    "    missense_df['POS_AA'] = aa_info[1]  # Amino acid position (optional)\n",
    "    # Save to new TSV\n",
    "    missense_df.to_csv(output_tsv, sep='\\t', index=False)\n",
    "    print(f\"Found {len(missense_df)} missense variants\")\n",
    "    print(\"Sample output:\")\n",
    "    print(missense_df[['PROT', 'REF_AA', 'ALT_AA']].head())\n",
    "    return missense_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_file = \"/share/yu/mw2243/HGMD/parsed_variants.tsv\"\n",
    "output_file = \"/share/yu/mw2243/HGMD/missense_variants.tsv\"\n",
    "result_df = extract_missense_variants(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d74805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_nonsense_variants(input_tsv, output_tsv):\n",
    "    # Read the parsed TSV file\n",
    "    df = pd.read_csv(input_tsv, sep='\\t')\n",
    "    # Define the missense mutation pattern\n",
    "    nonsense_pattern = r'.+:p.[A-Z]\\d+\\*'\n",
    "    # Create mask for rows with valid missense mutations\n",
    "    nonsense_mask = df['PROT'].str.contains(nonsense_pattern, na=False)\n",
    "    # Subset the dataframe\n",
    "    nonsense_df = df[nonsense_mask].copy()\n",
    "    # Save to new TSV\n",
    "    #missense_df.to_csv(output_tsv, sep='\\t', index=False)\n",
    "    print(f\"Found {len(nonsense_df)} nonsense variants\")\n",
    "    print(\"Sample output:\")\n",
    "    #print(missense_df[['PROT', 'REF_AA', 'ALT_AA']].head())\n",
    "    return nonsense_df\n",
    "\n",
    "input_file = \"/share/yu/mw2243/HGMD/parsed_variants.tsv\"\n",
    "output_file = \"/share/yu/mw2243/HGMD/nonsense_variants.tsv\"\n",
    "result_df = extract_nonsense_variants(input_file, output_file)\n",
    "result_df.to_csv(output_file,sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760ca605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding indels\n",
    "coding_indels = parsed_res[\n",
    "    (parsed_res['REF'].str.len() != parsed_res['ALT'].str.len()) & \n",
    "    (parsed_res['PROT'].values!=None)\n",
    "]\n",
    "coding_indels.to_csv(\"/share/yu/mw2243/HGMD/coding_indels.tsv\", sep='\\t', index=False)\n",
    "\n",
    "noncoding = parsed_res[\n",
    "    (parsed_res['PROT'].values==None)\n",
    "]\n",
    "noncoding.to_csv(\"/share/yu/mw2243/HGMD/non_coding.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671267bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the main parsed variants file\n",
    "main_df = pd.read_csv(\"/share/yu/mw2243/HGMD/parsed_variants.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Initialize a set to store all IDs from the other files\n",
    "known_ids = set()\n",
    "\n",
    "# List of files containing known variant types\n",
    "known_files = [\n",
    "    \"/share/yu/mw2243/HGMD/non_coding.tsv\",\n",
    "    \"/share/yu/mw2243/HGMD/missense_variants.tsv\",\n",
    "    \"/share/yu/mw2243/HGMD/nonsense_variants.tsv\",\n",
    "    \"/share/yu/mw2243/HGMD/coding_indels.tsv\"\n",
    "]\n",
    "\n",
    "# Collect all IDs from the known files\n",
    "for file in known_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, sep=\"\\t\")\n",
    "        if 'ID' in df.columns:\n",
    "            known_ids.update(df['ID'].dropna().astype(str))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Filter main dataframe for variants not in any known category\n",
    "other_variants = main_df[~main_df['ID'].isin(known_ids)]\n",
    "\n",
    "# Save to new file\n",
    "other_variants.to_csv(\"/share/yu/mw2243/HGMD/other_variants.tsv\", sep=\"\\t\", index=False)\n",
    "print(f\"Saved {len(other_variants)} other variants to /share/yu/mw2243/HGMD/other_variants.tsv\")\n",
    "print(f\"Total original variants: {len(main_df)}\")\n",
    "print(f\"Known variants: {len(known_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eea0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in: \"/share/yu/mw2243/HGMD/parsed_variants.tsv\"\n",
    "# based on ID of the following files,\n",
    "# \"/share/yu/mw2243/HGMD/non_coding.tsv\"\n",
    "# \"/share/yu/mw2243/HGMD/missense_variants.tsv\"\n",
    "# \"/share/yu/mw2243/HGMD/nonsense_variants.tsv\"\n",
    "# \"/share/yu/mw2243/HGMD/coding_indels.tsv\"\n",
    "# save rest rows to /share/yu/mw2243/HGMD/other_variants.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b2f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missense \n",
    "# non-sense mutation: r'.+:p.[A-Z]\\d+\\*'\n",
    "# coding indels: From the parsed data frame, pick out variants whose REF_N and ALT_N have different length and RefSeq_protein_record is not nan.\n",
    "# noncoding variants\n",
    "# remaining variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778822ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count frequency\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionary to store counts\n",
    "category_counts = {}\n",
    "\n",
    "# List of files with their categories\n",
    "variant_files = {\n",
    "    \"non_coding\": \"/share/yu/mw2243/HGMD/non_coding.tsv\",\n",
    "    \"missense\": \"/share/yu/mw2243/HGMD/missense_variants.tsv\",\n",
    "    \"nonsense\": \"/share/yu/mw2243/HGMD/nonsense_variants.tsv\", \n",
    "    \"coding_indels\": \"/share/yu/mw2243/HGMD/coding_indels.tsv\",\n",
    "    \"other_variants\": \"/share/yu/mw2243/HGMD/other_variants.tsv\"\n",
    "}\n",
    "\n",
    "# Count rows in each file\n",
    "for category, filepath in variant_files.items():\n",
    "    try:\n",
    "        # Only read first column to be memory efficient\n",
    "        df = pd.read_csv(filepath, sep='\\t', usecols=[0]) \n",
    "        category_counts[category] = len(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error counting {category}: {e}\")\n",
    "        category_counts[category] = 0\n",
    "\n",
    "# Print results        \n",
    "print(\"Variant Category Counts:\")\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"{category:>15}: {count:>6,} rows\")\n",
    "\n",
    "# Calculate and print total\n",
    "total = sum(category_counts.values())\n",
    "print(f\"{'Total':>15}: {total:>6,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = {}\n",
    "variant_files = {\n",
    "    \"mapped coding_indels\":\"/share/yu/mw2243/HGMD/processed/mapped_coding_indel.txt\",\n",
    "    \"mapped missense\":\"/share/yu/mw2243/HGMD/processed/mapped_missense.txt\",\n",
    "    \"mapped nonsense\":\"/share/yu/mw2243/HGMD/processed/mapped_nonsense.txt\",\n",
    "    \"non_coding\": \"/share/yu/mw2243/HGMD/processed/non_coding.tsv\",\n",
    "    \"other variants\":\"/share/yu/mw2243/HGMD/processed/other_variants.tsv\",\n",
    "    \"unmapped coding_indels\":\"/share/yu/mw2243/HGMD/processed/unmapped_coding_indel.txt\",\n",
    "    \"unmapped missense\":\"/share/yu/mw2243/HGMD/processed/unmapped_missense.txt\",\n",
    "    \"unmapped nonsense\":\"/share/yu/mw2243/HGMD/processed/unmapped_nonsense.txt\"\n",
    "}\n",
    "\n",
    "# Count rows in each file\n",
    "for category, filepath in variant_files.items():\n",
    "    try:\n",
    "        # Only read first column to be memory efficient\n",
    "        df = pd.read_csv(filepath, sep='\\t', usecols=[0]) \n",
    "        category_counts[category] = len(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error counting {category}: {e}\")\n",
    "        category_counts[category] = 0\n",
    "\n",
    "# Print results        \n",
    "print(\"Variant Category Counts:\")\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"{category:>15}: {count:>6,} rows\")\n",
    "\n",
    "# Calculate and print total\n",
    "total = sum(category_counts.values())\n",
    "print(f\"{'Total':>15}: {total:>6,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6d82d",
   "metadata": {},
   "source": [
    "category: total (mapped + unmapped to (uniprot))\n",
    "\n",
    "missense: 261500 rows (261346 + 154)\n",
    "\n",
    "nonsense: 54675 rows (54648 + 27)\n",
    "\n",
    "coding_indels: 103732 rows (101769 + 1963)\n",
    "\n",
    "non_coding: 58607 rows \n",
    "\n",
    "other_variants: 24613 rows"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
